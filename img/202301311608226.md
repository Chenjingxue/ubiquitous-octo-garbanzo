# Clues Before Answers: Generation-Enhanced Multiple-Choice QA

全文中心：本文提出了一个名为GenMC的生成增强MCQA模型，从问题中生成线索，然后利用线索来增强MCQA的阅读器。

# 1 Introduction

在分类和回归任务中，解码器层往往没有得到充分利用。本文研究的一个问题是如何以更自然的方式将预训练的编码器-解码器模型应用于MCQA，特别是利用它们的**NLG功能**。对于简单的问题，线索可能就是正确答案，而对于复杂的问题，线索可能起到辅助作用，帮助人们将问题与正确答案联系起来。

![image-20221217164953294](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221217164953294.png)

**GenMC模型：**

作者建议使用预先训练的编码器-解码器模型，通过利用问题的潜在知识从问题中生成线索，而不是严格限制在选项中。然后，基于编码器的模型利用线索表示来读取选项并进行预测。我们将这个代增强的MCQA模型称为GenMC。

# 2 Related Work

**2.1 Text-to-Text Paradigm for MCQA**

![image-20221217170614082](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221217170614082.png)

问题Q和所有选项{O1, O2, O3, O4}拼接成一个文本作为输入，训练一个text to text 模型，正确答案O1作为生成目标。

好处是：大量的训练数据可以在不同的任务之间共享。使用这样的框架，UnifiedQA将20个QA数据集集成到统一的格式进行训练，并在多个MCQA数据集上实现了最先进的结果。但是通过生成目标训练分类任务是否合适可能是有争议的。

**2.2 Encoder-Only Paradigm for MCQA**

![image-20221217171440179](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221217171440179.png)

现仅编码器范例：问题Q与{O1, O2, O3, O4}中的每个选项相互作用计算得分，并选择得分最高的选项作为答案。

在此基础上，一些工作研究了如何设计更好的基于注意力的模型来识别证据。其他努力模仿人类阅读证据和回答问题的行为 。在那里，证据来自给定的文章或从外部语料库检索。相比之下，我们的目标是从预先训练的模型中导出线索，而不需要求助于额外的来源。

# **3 GenMC Model**

本文提出的模型GenMC在预训练编码器-解码器模型的基础上，GenMC首先生成指示正确答案的线索，从而利用预训练编码器-解码器模型的NLG功能和底层知识。然后，GenMC将生成的线索表示作为连接问题和正确答案的中间知识，与读者进行交互，增强读者的答题能力。我们的模型设计模仿人类如何解决MCQA任务，即，在阅读一个问题后，人类可能首先将它与他们的一些背景知识联系起来(即寻找线索)，这有助于他们随后确定正确的答案。

![image-20221217174301899](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221217174301899.png)

**3.1 Clue Generator**

线索生成器将问题Q作为输入，并自回归输出线索C = c1，……， c| c|使用预训练的编解码器模型。值得注意的是，在我们的模型中使用的不是线索文本C，而是它的表示HC。具体来说，作者分别从编码器的最后一层和解码器的最后一层获得问题表示HQ和线索表示HC。HCj表示第j个令牌cj∈C的表示，计算公式如下:

![image-20221217175020755](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221217175020755.png)

其中HQ作为输入，HCj作为第j个线索（作为输出隐藏状态），Pcj表示第j步解码词汇的概率分布。

为了鼓励C中的令牌彼此之间以及与Q进行彻底的交互，我们通过将其传递给Transformer层来加强线索表示，并获得HQC:

![image-20221217182558265](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221217182558265.png)

HQC携带着C的信息，有助于更好地理解和回答Q。

**3.2 Enhanced Reader**

作者使用先前生成的线索表示来增强读者对每个问题-选项对的更深入理解。具体来说，我们首先将Q和每个Oi独立连接，并将连接的输入输入到预训练的编码器(与我们的线索生成器共享)，以获得Oi的情境表示为HQO（i），其次，基于线索表示HQC，我们的模型密集读取每个问题-选项对，获得线索与选项之间的匹配信号。具体而言，首先使用双重注意力来融合从HQO i到HQC以及从HQC到HQO i的信息。然后我们执行max-pooling来聚合匹配的特征:

![image-20221219152944524](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221219152944524.png)

为了获得每个Oi的最终得分si，我们将双匹配特征f QO i和f QC i连接起来，并将它们输入一个两层多层感知器(MLP即记分器):

![image-20221219153057874](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221219153057874.png)

最后，选择得分最高的选项作为预测答案，记为Op。

**3.3 Training Objective**

作者以端到端的方式联合训练线索生成器和增强阅读器，损失为:

![image-20221219162544605](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221219162544605.png)

![image-20221219162819894](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221219162819894.png)

其中pOt j表示第j步解码词汇表的概率分布，pOt j,aj是令牌aj的概率。

![image-20221219162946086](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221219162946086.png)

值得注意的是，我们使用联合损耗L更新编码器，同时我们不允许LREAD反向传播到解码器部分以减少内存消耗。

上述训练目标利用了MCQA中正确答案Ot的双重属性:**文本属性和索引属性**。我们使用Ot作为文本来监督我们的线索生成器，并使用Ot作为索引(即分类标签)来监督我们的增强阅读器。

# **4 Experimental Setup**

作者使用Adam优化器并设置预热分数= 0.1，权重衰减= 0.01，最大源长度= 64，最大目标长度= 32,epoch = 30，并在5个epoch后在开发集上没有更好的结果时提前停止训练。对于每个模型，从{1e−4,5e−5,1e−5}中寻找最佳学习率，并从{8,64}中寻找最佳批处理大小。

由于神经模型已知对不同的随机种子敏感，特别是当训练集很小时，作者对具有不同随机种子的所有模型进行了多次实验，并报告了均值和标准差。对于CSQA、OBQA、ARC-Easy和QASC，使用了三个随机种子{1,10,20}。对于最小的数据集ARC-Challenge，使用了五个随机种子{1,10,20,30,40}。

# 5 Experimental Results

**5.1 Main Results: Comparison with Text-to-Text Models**

为了实证地评估GenMC是否更好地利用了MCQA预训练的编码器-解码器模型的潜力，作者将GenMC与标准的文本到文本实现及其变体进行比较分析。

<img src="C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221219164442364.png" alt="image-20221219164442364"  />

结果表明，在所有数据集上，GenMC一致且显著优于Text2Textvanilla和Text2Textenc。在一些设置中，GenMC甚至获得了超过10%的绝对增益。例如，在具有挑战性的科学MCQA数据集ARC-Challenge的测试集上，T5BASE + GenMC将T5BASE + Text2Textvanilla的准确率从23.69%提高到39.00%。这些结果表明，GenMC是一种比现有的预训练编码器-解码器模型更有效的使用。

在超过一半的实验中，无解码器基线Text2Textenc优于Text2Textvanilla。这表明解码器从预训练中获得的一般语言知识在很大程度上被浪费了，仅仅将其用作分类器，这可能进一步解释了我们的模型的优越性能。

**5.2 Comparison with Other Models**

![image-20221219165536198](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221219165536198.png)

表3中的结果显示，GenMCT5显著(p值< 0.01)优于两个仅使用编码器的强基线RoBERTa和ALBERT。更有趣的是，GenMCT5在大多数数据集上的表现也优于UnifiedQAT5。

![image-20221219165728702](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221219165728702.png)

作为表4中更公平的比较，通过统一所有五个数据集的训练集，我们的GenMCT5-U在除CSQA大模型外的所有数据集上都优于UnifiedQAT5-FT。

**5.3 Ablation Study: Influence of Clues**

为了更好地理解其优越的结果和我们的线索生成的影响，我们比较了两种变体。

**Weak Clue** ：我们只使用分类损失LREAD来训练这个变体，因此只有编码器部分被更新，而解码器部分在预训练中保持不变。直观地，在这种设置下，生成的线索比GenMC弱，GenMC学习如何在监督下生成线索。

**Token Clue：**在这个设置中，我们分别训练线索生成器和读取器。我们首先从解码器收集生成的线索文本C(而不是它的表示)。然后，我们直接将C与Q和Oi连接起来，使用与MLP层堆叠的模型编码器部分来计算Oi的得分。

![image-20221219170654015](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221219170654015.png)

表5显示，屏蔽生成损失会导致所有数据集的性能大幅下降，表明使用生成损失L GEN微调解码器有助于从预训练的编码器-解码器模型中获得有用的线索。作者还观察到，使用令牌级线索的性能远远落后于GenMC。

